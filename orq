#!/usr/bin/python
# vim: sw=2 et

__author__ = "David Reiss <davidn@gmail.com>"

import os, sys, json, socket, SocketServer, threading, subprocess, time
import tempfile, shutil, traceback

IS_ROOT = os.getuid() == 0

ORQ_PORT = 4999
REG_PORT = 5000
if IS_ROOT:
  PUBLIC_PORT = 80
  PUBLIC_SSL_PORT = 443
  ORQ_ROOT = '/var/lib/orq'
  DEBUG = False
else:
  PUBLIC_PORT = 8000
  PUBLIC_SSL_PORT = 8443
  ORQ_ROOT = os.path.join(os.getenv('HOME'), '.orq')
  DEBUG = True
STATE_FILE = os.path.join(ORQ_ROOT, 'state')
VOL_ROOT = os.path.join(ORQ_ROOT, 'volumes')
LOCALHOST = '127.0.0.1'
ORQ_ADDR = (LOCALHOST, ORQ_PORT)
CHECK_INTERVAL = 10
FORCE_SSL = 'FORCE_SSL'

# Change this when changing any of:
# - nginx Dockerfile
# - default task structs
VERSION = 6

NGINX_TASK_NAME = '__nginx__'
NGINX_IMAGE_NAME = 'orq_nginx_%d' % VERSION
NGINX_CONFIG_VOL = 'proxy_config'
NGINX_CERTS_VOL = 'proxy_ssl_certs'
NGINX_TASK = {
    'name': NGINX_TASK_NAME,
    'raw_image_name': NGINX_IMAGE_NAME,
    'volumes': [
      {'id': NGINX_CONFIG_VOL, 'container': '/etc/nginx'},
      {'id': NGINX_CERTS_VOL, 'container': '/certs'},
      {'id': 'proxy_logs', 'container': '/var/log/nginx'},
      ],
    'exposed_ports': [
      {'host': PUBLIC_PORT, 'container': 8000, 'public': True},
      {'host': PUBLIC_SSL_PORT, 'container': 8443, 'public': True},
      ],
    'stop_old_first': True,
    'caps': 'setuid setgid chown dac_override'.split(),
    }

REGISTRY_TASK_NAME = '__registry__'
REGISTRY_TASK = {
    'name': REGISTRY_TASK_NAME,
    'raw_image_name': 'registry:2',
    'env': {
      'REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY': '/data',
      },
    'volumes': [
      {'id': 'docker_registry2_data', 'container': '/data'}
      ],
    'exposed_ports': [
      {'host': REG_PORT, 'container': REG_PORT},
      ],
    'stop_old_first': True,
    }

NGINX_IMAGE_SOURCES = {

'Dockerfile': r'''
FROM ubuntu:18.04
ARG date=2020-04-07
ARG DEBIAN_FRONTEND=noninteractive
RUN apt-get -y update && apt-get -y upgrade && apt-get -y install nginx
EXPOSE 8000 8443
VOLUME /etc/nginx /var/log/nginx /certs
CMD nginx
''',

}


# We want to set a default server for nginx so that requests without a host get
# a 404. To do that over ssl, we need to present some cert. So here's a cert.
DUMMY_CERT = '''-----BEGIN CERTIFICATE-----
MIIB7jCCAVegAwIBAgIJAMyHwAmYdTWjMA0GCSqGSIb3DQEBCwUAMBAxDjAMBgNV
BAMMBWR1bW15MB4XDTE0MDUxMjAyMjcyMVoXDTI0MDUwOTAyMjcyMVowEDEOMAwG
A1UEAwwFZHVtbXkwgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAK8NqQh/CHQg
Fa8X8ge/3Dvq26gjX659S7SsSHriIQq6ebl4sunccjOF9akvi01buBgJS5DH3XYM
AyEk3iDRYff8QpPYmcthjkI6SsEE5opmzGhBsLz+m/Lpcuo36j5pDW7pHGKC+yug
ARCTGmTidMk1ADuij3G6cOEKTp4NMFdtAgMBAAGjUDBOMB0GA1UdDgQWBBSUswAf
QWEn2hFdDTpvnoAFuHXZWTAfBgNVHSMEGDAWgBSUswAfQWEn2hFdDTpvnoAFuHXZ
WTAMBgNVHRMEBTADAQH/MA0GCSqGSIb3DQEBCwUAA4GBAHxt3WOiJLCTWIg3MV9q
TyE4agSJrSCNU7XHziVsVfDC3ez74fQLbRiD/ZCiDW03pMFD1ludz3G0bpspAiGB
+rrOy0nVHLd1Kv7S5vOicfYfxyEJ66bWtaofVUb8eOuy8eahbcXJK0PiVTfZepTT
aTE7X9vqbOuh5D87P0JhHT+f
-----END CERTIFICATE-----
'''
DUMMY_KEY = '''-----BEGIN PRIVATE KEY-----
MIICdgIBADANBgkqhkiG9w0BAQEFAASCAmAwggJcAgEAAoGBAK8NqQh/CHQgFa8X
8ge/3Dvq26gjX659S7SsSHriIQq6ebl4sunccjOF9akvi01buBgJS5DH3XYMAyEk
3iDRYff8QpPYmcthjkI6SsEE5opmzGhBsLz+m/Lpcuo36j5pDW7pHGKC+yugARCT
GmTidMk1ADuij3G6cOEKTp4NMFdtAgMBAAECgYAjvy9ga8iHJjInYkVrbbOEjM40
RJz6Xd3C1FesuFa1ASVwSYSHmxu7B8UFuo7AylUKm4NR2m6P953/+65cl0Vg7x7m
nDmKjayTDgZvQbTdOZdzmFR1h3B+mcSQ4n4mDZeHjv3Qafo40Jpfgsc6F5gkdv5Y
rgtnuKJNY1gCZgUmQQJBANuwue3/SoDvkxTp46FpGSWRAU3+1ASSdxB1gb6wp8ld
M5TVv7xE4i4AtzjTeM3sQdHsYJGuEtcbKyk0d0tJWR0CQQDL/E7PTc0ooxuryWXj
f0yYbVMZuMySjNIrriUtb6yM36sM3HarWIWSAApxlLO/3XCynlXAD02iFhGW2xuk
n/aRAkA3IgfXOY06BGW2Buhwdo6wBc79Aum0aAlnYQX5lB3XhANQ47+lgOf+QYG5
yiB0FUmDZD3r8XKa9x+CzL7vbu3lAkEAxaIGmUM/6oddX+sZFHlZtLT3NoydZ7+Y
QUnQK11vSG3MRAG11/1ELFhtxe3U2aeqcOSHIDWzeb73+7j951o0gQJARJZZZP6T
wwWKvZWQsZfIFJbSqh/oNuZTivzW3o5XulOU78YD4BTanVvbC0TkMGmDHT+oOMq5
7iCwLAUvvA+t3g==
-----END PRIVATE KEY-----
'''


class DockerError(Exception): pass
class InspectError(DockerError): pass

def volume_path(vid):
  return os.path.join(VOL_ROOT, vid)

def cert_key_paths(domain):
  certs_path = volume_path(NGINX_CERTS_VOL)
  cert = os.path.join(certs_path, domain + '.crt')
  key  = os.path.join(certs_path, domain + '.key')
  return cert, key

def docker(*argv):
  argv = list(argv)
  argv[0:0] = ['docker']
  if DEBUG:
    print '+', ' '.join(argv)
  try:
    return subprocess.check_output(argv)
  except subprocess.CalledProcessError:
    raise DockerError

def inspect(thing, *keys):
  try:
    data = json.loads(docker('inspect', thing))
    data = data[0]
    for k in keys:
      data = data[k]
    return data
  except (DockerError, IndexError, KeyError, TypeError):
    raise InspectError

def ipaddr_of(cid):
  return inspect(cid, 'NetworkSettings', 'IPAddress')

def image_in_registry(image):
  if '/' in image:
    return image
  else:
    return 'localhost:%d/%s' % (REG_PORT, image)

def do_client(data):
  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  s.connect(ORQ_ADDR)
  s.sendall(json.dumps(data))
  s.shutdown(socket.SHUT_WR)
  return json.load(s.makefile('r'))

def print_json(out):
  json.dump(out, sys.stdout, sort_keys=True,
      indent=4, separators=(',', ': '))
  print

def get_public_ip(cache=[]):
  # TODO: this needs to be more robust
  if not cache:
    cmd = r"ifconfig eth0 | sed -ne 's/.* inet addr:\([0-9.]*\).*/\1/p'"
    output = subprocess.check_output(cmd, shell=True)
    cache.append(output.strip())
  return cache[0]

def write_cert_key(domain, cert, key):
  cert_path, key_path = cert_key_paths(domain)
  open(cert_path, 'w').write(cert)
  if key:
    open(key_path, 'w').write(key)

def gen_nginx_config(servers):
  def make_server(domain, backend_ip, backend_port, ssl):
    sslcerts = '''
          ssl_certificate /certs/%(domain)s.crt;
          ssl_certificate_key /certs/%(domain)s.key;
    ''' % vars()
    proxy = '''
          location / {
            proxy_pass http://%(backend_ip)s:%(backend_port)s;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_read_timeout 1h;
          }
    ''' % vars()
    if ssl == FORCE_SSL:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
          return 301 https://$host$request_uri;
        }
        server {
          server_name %(domain)s;
          listen 8443 ssl;
%(sslcerts)s
%(proxy)s
        }
      ''' % vars()
    elif ssl:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
          listen 8443 ssl;
%(sslcerts)s
%(proxy)s
        }
      ''' % vars()
    else:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
%(proxy)s
        }
      ''' % vars()

  server_blocks = ''.join(make_server(*s) for s in servers)

  return '''
    daemon off;
    user www-data;
    worker_processes 4;
    pid /dev/null;
    error_log stderr;
    events {
      worker_connections 4000;
    }
    worker_rlimit_nofile 9000;
    http {
      map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
      }
      access_log /var/log/nginx/access.log;
      error_log /var/log/nginx/error.log;
      proxy_buffering off;
      proxy_cache off;
      ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
      ssl_session_cache shared:SSL:5m;
      ssl_session_timeout 10m;
      add_header X-Frame-Options SAMEORIGIN;
      add_header X-Content-Type-Options nosniff;
      server_tokens off;
      server {
        listen 8000;
        listen 8443 ssl;
        ssl_certificate /certs/__dummy__.crt;
        ssl_certificate_key /certs/__dummy__.key;
        return 404;
      }
%(server_blocks)s
    }
  ''' % vars()


class ServerState(object):
  """
  schema:
  data = {
    'version': 1,
    'tasks': [
      {
        'task': <task json>,
        'cid': 'abc123', # or None
      },
    ],
  }
  """
  def tasks(self):
    return self.data['tasks']

  def find_tdata_by_name(self, name):
    for tdata in self.data['tasks']:
      if tdata['task']['name'] == name:
        return tdata

  def add_task(self, task):
    assert self.find_tdata_by_name(task['name']) is None
    tdata = {'task': task, 'cid': None}
    self.data['tasks'].append(tdata)
    return tdata

  def replace_task(self, old_name, new_task):
    old_tdata = self.find_tdata_by_name(old_name)
    if old_tdata:
      self.data['tasks'].remove(old_tdata)
      cid = old_tdata['cid']
      if cid:
        try: docker('stop', cid)
        except DockerError: pass
    self.add_task(new_task)

  def __enter__(self):
    try:
      self.data = json.load(open(STATE_FILE, 'r'))
      # migrations:
      if self.data['version'] == 5:
        self.replace_task('__nginx__', NGINX_TASK)
        self.data['version'] = 6

      # future migrations:
      # if self.data['version'] == ...

    except IOError:
      self.data = {'version': VERSION, 'tasks': []}
      self.add_task(NGINX_TASK)
      self.add_task(REGISTRY_TASK)
    return self

  def save(self):
    json.dump(self.data, open(STATE_FILE + '.tmp', 'w'))
    os.rename(STATE_FILE + '.tmp', STATE_FILE)

  def __exit__(self, t, v, t2):
    self.save()


class ServerHandler(SocketServer.StreamRequestHandler):
  def handle(self):
    try:
      data = json.load(self.rfile)
      result = getattr(self, 'op_' + data['op'])(data)
      out = {'success': True, 'result': result}
      json.dump(out, self.wfile)
    except:
      tb = traceback.format_exc()
      sys.stderr.write(tb + '\n')
      out = {'success': False, 'error': tb}
      json.dump(out, self.wfile)

  @staticmethod
  def get_image_name(task):
    if task.get('raw_image_name'):
      return task['raw_image_name']
    else:
      return image_in_registry(task['name'])

  @staticmethod
  def construct_docker_args(task):
    args = []

    args.append('-d')

    args.append('--cap-drop=all')
    for cap in task.get('caps', []):
      args.append('--cap-add='+cap)

    for vol in task.get('volumes', []):
      args.append('-v')
      host = volume_path(vol['id'])
      args.append('%s:%s' % (host, vol['container']))

    for port in task.get('exposed_ports', []):
      host = port['host']
      container = port['container']
      if port.get('public'):
        expose_ip = get_public_ip()
      else:
        expose_ip = LOCALHOST
      args.append('-p')
      args.append('%s:%s:%s' % (expose_ip, host, container))

    for k, v in task.get('env', {}).items():
      args.append('-e')
      args.append('%s=%s' % (k, v))

    args.append(ServerHandler.get_image_name(task))

    args.extend(task.get('argv', []))

    return args

  @staticmethod
  def ensure_host_volumes(task):
    for vol in task.get('volumes', []):
      path = volume_path(vol['id'])
      if not os.path.isdir(path):
        os.makedirs(path)
        os.chmod(path, 01777)

  @staticmethod
  def reconfigure_proxy(st):
    servers = []
    for tdata in st.tasks():
      task = tdata['task']
      domain = task.get('domain')
      port = task.get('http_port')
      if domain and port:
        ip = ipaddr_of(tdata['cid'])
        cert_path, key_path = cert_key_paths(domain)
        if task.get('force_ssl'):
          ssl = FORCE_SSL
        else:
          ssl = bool(task.get('ssl_cert') and
              os.path.exists(cert_path) and os.path.exists(key_path))
        servers.append((domain, ip, port, ssl))
    cfg = gen_nginx_config(servers)

    fn = os.path.join(volume_path(NGINX_CONFIG_VOL), 'nginx.conf')
    open(fn, 'w').write(cfg)
    os.chmod(fn, 0644)

    ServerHandler.hup_nginx(st)

  @staticmethod
  def hup_nginx(st):
    nginx_cid = st.find_tdata_by_name(NGINX_TASK_NAME)['cid']
    if nginx_cid:
      try: docker('kill', '-s', 'HUP', nginx_cid)
      except DockerError: pass

  def op_check_running(self, data):
    with ServerState() as st:
      for task in st.data['tasks']:
        cid = task['cid']
        try:
          if cid and inspect(cid, 'State', 'Running'):
            continue
        except InspectError:
          pass
        self.run_task(st, task['task'])
        st.save()

  def run_task(self, st, task):
    # pull latest first
    if not task.get('raw_image_name'):
      docker('pull', ServerHandler.get_image_name(task))

    stop_old_first = task.get('stop_old_first', False)

    self.ensure_host_volumes(task)

    # if we're running the proxy, ensure we have a config
    if task['name'] == NGINX_TASK_NAME:
      write_cert_key('__dummy__', DUMMY_CERT, DUMMY_KEY)
      ServerHandler.reconfigure_proxy(st)

    # add to state and get old cid
    tdata = st.find_tdata_by_name(task['name'])
    if not tdata:
      tdata = st.add_task(task)
    tdata['task'] = task
    old_cid = tdata['old_cid'] = tdata['cid']

    # check if the container is already running the new image
    try:
      if old_cid and inspect(old_cid, 'State', 'Running'):
        running_image = inspect(old_cid, 'Image')
        new_image = inspect(self.get_image_name(task), 'Id')
        if running_image == new_image:
          return
    except InspectError:
      pass

    # take down old thing (if before)
    if stop_old_first and old_cid:
      try: docker('stop', old_cid)
      except DockerError: pass

    # run new thing
    args = self.construct_docker_args(task)
    tdata['cid'] = docker('run', *args).strip()

    time.sleep(task.get('up_wait_time', 1))

    # point nginx to new thing
    if 'domain' in task:
      ServerHandler.reconfigure_proxy(st)

    # take down old thing (if after)
    if not stop_old_first and old_cid:
      time.sleep(task.get('down_wait_time', 1))
      docker('stop', old_cid)

  def op_ping(self, data):
    return None

  def op_run(self, data):
    task = data['task']
    with ServerState() as st:
      self.run_task(st, task)

  def op_stop(self, data):
    name = data['task']['name']  # only pull out name, ignore rest
    with ServerState() as st:
      tdata = st.find_tdata_by_name(name)
      if tdata:
        task = tdata['task']
        cid = tdata['cid']
        if cid:
          docker('stop', cid)
        st.data['tasks'].remove(tdata)
        if 'domain' in task:
          ServerHandler.reconfigure_proxy(st)

  def op_upload_cert(self, data):
    write_cert_key(data['task']['domain'], data['cert'], data['key'])
    with ServerState() as st:
      ServerHandler.hup_nginx(st)

  def op_cleanup(self, data):
    subprocess.call('''
      # delete all non-running container
      docker ps -a | awk '/Exit/ {print $1}' | xargs -r docker rm
      # delete unused images
      docker images | awk '/<none>/ {print $3}' | xargs -r docker rmi
    ''', shell=True)


def build_local_image(sources, name):
  tmpdir = tempfile.mkdtemp()
  os.chdir(tmpdir)
  for k, v in sources.items():
    open(k, 'w').write(v)
  docker('build', '--rm', '-t', name, '.')
  os.chdir('/')
  shutil.rmtree(tmpdir)


def run_daemon():
  # build nginx image
  try:
    inspect(NGINX_IMAGE_NAME, 'config')
  except InspectError:
    build_local_image(NGINX_IMAGE_SOURCES, NGINX_IMAGE_NAME)

  # set up for daemon
  os.umask(077)
  for d in ORQ_ROOT, VOL_ROOT:
    if not os.path.isdir(d):
      os.makedirs(d)
  os.chdir(ORQ_ROOT)

  def send_check_requests():
    time.sleep(1)
    while True:
      try: do_client({'op': 'check_running'})
      except: pass
      time.sleep(CHECK_INTERVAL)
  scr = threading.Thread(target=send_check_requests)
  scr.setDaemon(True)
  scr.start()

  SocketServer.TCPServer(ORQ_ADDR, ServerHandler).serve_forever()


class SshTunnel(object):
  def __init__(self, host):
    self.host = host

  def __enter__(self):
    args = [
        'ssh',
        self.host,
        '-L', 'localhost:%d:127.0.0.1:%d' % (ORQ_PORT, ORQ_PORT),
        '-L', 'localhost:%d:127.0.0.1:%d' % (REG_PORT, REG_PORT),
        'sleep 1d',
        ]
    self.proc = subprocess.Popen(args,
        close_fds=True,
        stdin=open('/dev/null', 'r'),
        stdout=open('/dev/null', 'w'))
    while True:
      try:
        do_client({'op': 'ping'})
        break
      except socket.error:
        time.sleep(1)

  def __exit__(self, t, v, t2):
    self.proc.terminate()
    self.proc.wait()


class Cli(object):
  def handle(self, argv):
    return getattr(self, 'cmd_' + argv[0])(argv[1:])

  @staticmethod
  def load_taskfile(argv):
    tasks = json.load(open(argv[0], 'r'))
    if len(argv) > 1:
      tasks = filter(Cli.task_matcher(argv[1:]), tasks)
    return tasks

  @staticmethod
  def task_matcher(words):
    return lambda task: any(word in task['name'] for word in words)

  def cmd_daemon(self, argv):
    run_daemon()

  def cmd_run(self, argv):
    tasks = self.load_taskfile(argv)

    print "==== BUILDING"
    for task in tasks:
      if 'dockerdir' in task:
        dockerdir = os.path.join(os.path.dirname(argv[0]), task['dockerdir'])
        image = task['name']
        regimage = image_in_registry(image)
        docker('build', '-t', image, dockerdir)
        docker('tag', image, regimage)

    byhost = {}
    for task in tasks:
      byhost.setdefault(task['host'], []).append(task)
    byhost = byhost.items()

    print "==== PUSHING"
    for host, tasks in byhost:
      with SshTunnel(host):
        for task in tasks:
          if 'dockerdir' in task:
            docker('push', image_in_registry(task['name']))

    print "==== RUNNING"
    for host, tasks in byhost:
      with SshTunnel(host):
        for task in tasks:
          print_json(do_client({'op': 'run', 'task': task}))

  def cmd_upload_cert(self, argv):
    tasks = self.load_taskfile(argv)
    for task in tasks:
      if not task.get('ssl_cert') or not task.get('domain'):
        continue
      host = task['host']
      with SshTunnel(host):
        cert_file = os.path.join(os.path.dirname(argv[0]), task['ssl_cert'])
        key_file  = os.path.join(os.path.dirname(argv[0]), task['ssl_key'])
        cert = open(cert_file).read()
        try: key = open(key_file).read()
        except IOError: key = None
        print_json(do_client({'op': 'upload_cert', 'task': task,
                              'cert': cert, 'key': key}))

  def cmd_stop(self, argv):
    tasks = self.load_taskfile(argv)
    for task in tasks:
      host = task['host']
      with SshTunnel(host):
        print_json(do_client({'op': 'stop', 'task': task}))

  def cmd_ssh(self, argv):
    with SshTunnel(argv[0]):
      raw_input("ssh tunnel open; press enter to close")

  def cmd_cleanup(self, argv):
    with SshTunnel(argv[0]):
      print_json(do_client({'op': 'cleanup'}))


if __name__ == '__main__':
  sys.exit(Cli().handle(sys.argv[1:]))
