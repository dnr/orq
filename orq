#!/usr/bin/env -S python3 -u
# vim: sw=2 et

__author__ = "David Reiss <davidn@gmail.com>"

import os, sys, json, socket, socketserver, threading, subprocess, time
import tempfile, shutil, traceback, urllib.request

IS_ROOT = os.getuid() == 0

ORQ_PORT = 4999
REG_PORT = 5000
if IS_ROOT:
  PUBLIC_PORT = 80
  PUBLIC_SSL_PORT = 443
  ORQ_ROOT = '/var/lib/orq'
  DEBUG = False
else:
  PUBLIC_PORT = 8000
  PUBLIC_SSL_PORT = 8443
  ORQ_ROOT = os.path.join(os.getenv('HOME'), '.orq')
  DEBUG = True
STATE_FILE = os.path.join(ORQ_ROOT, 'state')
VOL_ROOT = os.path.join(ORQ_ROOT, 'volumes')
LOCALHOST = '127.0.0.1'
ORQ_ADDR = (LOCALHOST, ORQ_PORT)
CHECK_INTERVAL = 10
FORCE_SSL = 'FORCE_SSL'
USE_ACME = 'USE_ACME'

# Change this when changing any of:
# - nginx Dockerfile
# - default task structs
VERSION = 8

NGINX_TASK_NAME = '__nginx__'
NGINX_IMAGE_NAME = 'orq_nginx_%d' % VERSION
NGINX_CONFIG_VOL = 'proxy_config'
NGINX_CERTS_VOL = 'proxy_ssl_certs'
NGINX_TASK = {
    'name': NGINX_TASK_NAME,
    'raw_image_name': NGINX_IMAGE_NAME,
    'volumes': [
      {'id': NGINX_CONFIG_VOL, 'container': '/etc/nginx'},
      {'id': NGINX_CERTS_VOL, 'container': '/certs'},
      {'id': 'proxy_logs', 'container': '/var/log/nginx'},
      ],
    'exposed_ports': [
      {'host': PUBLIC_PORT, 'container': 8000, 'public': True},
      {'host': PUBLIC_SSL_PORT, 'container': 8443, 'public': True},
      ],
    'stop_old_first': True,
    'caps': 'setuid setgid chown dac_override'.split(),
    'restart_policy': 'unless-stopped',
    }

REGISTRY_TASK_NAME = '__registry__'
REGISTRY_TASK = {
    'name': REGISTRY_TASK_NAME,
    'raw_image_name': 'registry:2',
    'env': {
      'REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY': '/data',
      },
    'volumes': [
      {'id': 'docker_registry2_data', 'container': '/data'}
      ],
    'exposed_ports': [
      {'host': REG_PORT, 'container': REG_PORT},
      ],
    'stop_old_first': True,
    }

NGINX_IMAGE_SOURCES = {

'Dockerfile': '''
FROM ubuntu:20.04
ARG date=2020-12-10
ARG DEBIAN_FRONTEND=noninteractive
RUN apt-get -y update && apt-get -y upgrade && \
  apt-get -y install nginx acmetool ca-certificates
EXPOSE 8000 8443
VOLUME /etc/nginx /var/log/nginx /certs
ENV ACME_STATE_DIR=/certs/acmetool
COPY ./requestcerts /usr/bin/requestcerts
COPY ./reload /etc/acme/hooks/reload
COPY ./dummy.crt /etc/ssl/dummy/dummy.crt
COPY ./dummy.key /etc/ssl/dummy/dummy.key
CMD ["nginx"]
''',

'requestcerts': '''\
#!/bin/sh
set -e
cd /certs
for domain; do
  [ -e "${domain}.crt" ] || ln -snf "/etc/ssl/dummy/dummy.crt" "${domain}.crt"
  [ -e "${domain}.key" ] || ln -snf "/etc/ssl/dummy/dummy.key" "${domain}.key"
  [ -e "acmetool/live/${domain}" ] || acmetool --batch want --no-reconcile "${domain}"
done
''',

'reload': '''\
#!/bin/sh
set -e
cd /certs/acmetool/live
for domain in *; do
  test -e "${domain}" || continue
  ln -snf "acmetool/live/${domain}/fullchain" "/certs/${domain}.crt"
  ln -snf "acmetool/live/${domain}/privkey" "/certs/${domain}.key"
done
kill -HUP 1
''',

# We want to set a default server for nginx so that requests without a host get
# a 404. To do that over ssl, we need to present some cert. So here's a cert.
# generate with: openssl req -x509 -newkey rsa:2048 -keyout key.pem -out cert.pem -days 3650 -nodes -subj /CN=dummy
'dummy.crt': '''\
-----BEGIN CERTIFICATE-----
MIIDATCCAemgAwIBAgIUSZgaCILYRk3AIJZkHn/4SndptEEwDQYJKoZIhvcNAQEL
BQAwEDEOMAwGA1UEAwwFZHVtbXkwHhcNMjAwNzMxMjIwNzUzWhcNMzAwNzI5MjIw
NzUzWjAQMQ4wDAYDVQQDDAVkdW1teTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCC
AQoCggEBALrKRPG8ern/U6Qi4+f1OYvTlg0yEVf7K/JRj5iGOJ/1BNLkw0pnGCrU
uesG9nENPxd84Rx+2kG5xJkqwh0oYacpzoKmJZ7y0GCio5JiLnPqRT1z9BU8jBCP
PUUV/zJ9z0K//O4wFhFTMVLAX8R/vwAZnm/9x/tkO+flL3beohyFfcmUKOrMBDU2
1fAV+u+f9kXAiF67csBcLlZvPsjbKxKIxEJ16wkFRKf89GJ7VZjRh5KCjwb4lfyY
mDnBYfQWucUODOpRYVk5r4eq/Ca4I2TnEy27L45zw4b3JyTHYKZP/UlaizRCGtVn
uR+79UjUvn2VDENO8XaPUfXSd4S3hxkCAwEAAaNTMFEwHQYDVR0OBBYEFKwgB4qB
Q13CVRnCbXExA+1TqG4fMB8GA1UdIwQYMBaAFKwgB4qBQ13CVRnCbXExA+1TqG4f
MA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAKR8GYhtfcOc7Vzu
zCgSl7SUOG2lDDvr8nYVmnU+JpcnE7bQ4XafSyfV1+xHz2r014gqRrt4xgBjT5p7
E9GoDmd72iaUzsOi2jJKLCX5Lts3dqO2Q14nZ2ZF5oe31rTHK9kLi0l5CesD8QSI
nK7wA0jihRpWbZou1zwOjMOLAWmXSowSPDQaXwKgezQdUbIW74bEYQmDlrx8pZZj
v2qldY0c+CwHKWV02tCWlPT2gLt/o0wwj6dsSCZ4sdC4mb1TMN1ksUTVRyV1PO65
sNegwuaxK/BuMgi+6845Ed+CPKK1fijJ4qEODKyGPVksv0vd1iCkKkC/DA5PgYg5
ZyTRzFo=
-----END CERTIFICATE-----
''',

'dummy.key': '''\
-----BEGIN PRIVATE KEY-----
MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQC6ykTxvHq5/1Ok
IuPn9TmL05YNMhFX+yvyUY+Yhjif9QTS5MNKZxgq1LnrBvZxDT8XfOEcftpBucSZ
KsIdKGGnKc6CpiWe8tBgoqOSYi5z6kU9c/QVPIwQjz1FFf8yfc9Cv/zuMBYRUzFS
wF/Ef78AGZ5v/cf7ZDvn5S923qIchX3JlCjqzAQ1NtXwFfrvn/ZFwIheu3LAXC5W
bz7I2ysSiMRCdesJBUSn/PRie1WY0YeSgo8G+JX8mJg5wWH0FrnFDgzqUWFZOa+H
qvwmuCNk5xMtuy+Oc8OG9yckx2CmT/1JWos0QhrVZ7kfu/VI1L59lQxDTvF2j1H1
0neEt4cZAgMBAAECggEAO3xE/pMepnM4qNHvsKQ44l3MsIEcYt97fF0bFODR0acP
FTaDNwOj/6flWYLLIu+sAwfjDNcdHMdTY8/pJ63/g2Pd/194JamAUPYaj3izAHk/
+bUeq1Cv7mofggviTKsiQUiw/Q3VSUksMQVQulxQcHC4M0Qn1thx94TWW83E5L3V
/7UpKAywsbjt42CqotgKgKYrS4IUFWw+0rVrHVOOKXhAmDzRYthtiIgaVqlX+VEe
QtP0L9EJeyrK976kOctvcN2Qk1o0Q2e5o2KtTZcNdMKGq71rR6kVU4RYAF4NZ6oV
hKNmh6uMzsTyriO8Lkun7JKgf8cbTDY/WohPh25v/QKBgQD4+y++AEL1cwKrFuM6
qzn6I6YG92Z2knADbZ/SwGjBw/j48XEcE/FBFFePs9a6K7++2Pdv5efTFi71VuwI
JhYG2of3G1v+oruTD8qlJPNZlR189W0fRqyAKCipGpn65da+PaLTwFZLr8uKmoYG
y1eYcDmMojq0E0EDe0Sd25Y8iwKBgQDADkVNCLYQaNCo1tYej4GHmXQ7DQOeXT1z
QPlZSBxPwcHZqVcEwmXoga5cd4x/Oyig0yCXvefjUOz6IFOnABze34VxJAl4Ls7n
2LYNFvv1nX9vQqsfyI2EDYyxLfTBtlLjiKurZQeJTSh5AnbTfiQVdCaIqgaTImaW
AOGZu/7LawKBgH6/yO8tzOiNExesACN21X38teGoApZsN+/W19z/LJUvwchhiVZk
5JVf2K+EOtTtvqBWbaieXqT8Dw3AoUoIsX/tsfffCrcXeuwDxwLJS8UX/zoE6vdY
ECrxxrlHnIm4hdi1IfYwXP4M0U6PGZnN3JryzqlEUSQpBRjToPvHtLS/AoGADutM
4N4TXpT12JfPzFHzivgVulyZclzl4CUk+ZWLdXqkt2bbNqhvSC+CvvYeeOe8kTm1
Z3Q+Jj9sGUYXmXp9w6ZzdEWLYsWoFwSTp9KoQf05IAh6yJ5IuABhdIYQZFfoenps
c4UGn9jZkwTo/CbpYK1ELQugNR/P/kkVPV8IPP8CgYEAl1uPBBuI09unV0oJEjVI
ES2xtTEgu8NSz2vYvZlKqw/9MBicXQ61ZlwILBL9C90ZKV0t1K3yNhDytgSQhMpB
3Lkl6zSDh2fPY08Sc9J6bm2Mqa/RGkFb8ao8PrAiSTL8Zbvrr0sDyPzMMyx9V/Vq
Km84vSFFDk5cGRtU2wFYOIc=
-----END PRIVATE KEY-----
''',

}

CRASH_LOG_VOL = 'crash_logs'

class DockerError(Exception): pass
class InspectError(DockerError): pass

def ignore(_): pass

def volume_path(vid):
  return os.path.join(VOL_ROOT, vid)

def cert_key_paths(domain):
  certs_path = volume_path(NGINX_CERTS_VOL)
  cert = os.path.join(certs_path, domain + '.crt')
  key  = os.path.join(certs_path, domain + '.key')
  return cert, key

def docker(*argv):
  argv = list(argv)
  argv[0:0] = ['docker']
  if DEBUG:
    print('+', ' '.join(argv))
  try:
    return subprocess.check_output(argv).decode('utf-8')
  except subprocess.CalledProcessError:
    raise DockerError

def inspect(thing, *keys):
  try:
    data = json.loads(docker('inspect', thing))
    data = data[0]
    for k in keys:
      data = data[k]
    return data
  except (DockerError, IndexError, KeyError, TypeError):
    raise InspectError

def capture_logs(taskname, cid):
  time_cid = time.strftime('%Y%m%d-%H%M') + '-' + cid[:8]
  dir = os.path.join(volume_path(CRASH_LOG_VOL), taskname, time_cid)
  if not os.path.isdir(dir): os.makedirs(dir)
  with open(os.path.join(dir, 'inspect'), 'wb') as f:
    subprocess.call(['docker', 'inspect', cid], stdout=f)
  with open(os.path.join(dir, 'stdout'), 'wb') as out, \
       open(os.path.join(dir, 'stderr'), 'wb') as err:
    args = ['docker', 'logs', '--tail=1000', cid]
    subprocess.call(args, stdout=out, stderr=err)

def ipaddr_of(cid):
  return inspect(cid, 'NetworkSettings', 'IPAddress')

def image_in_registry(image):
  if '/' in image:
    return image
  else:
    return 'localhost:%d/%s' % (REG_PORT, image)

def do_client(data):
  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  s.connect(ORQ_ADDR)
  s.sendall(json.dumps(data).encode('utf-8'))
  s.shutdown(socket.SHUT_WR)
  return json.load(s.makefile('r'))

def print_json(out):
  json.dump(out, sys.stdout, sort_keys=True,
      indent=4, separators=(',', ': '))
  print()

def write_cert_key(domain, cert, key):
  cert_path, key_path = cert_key_paths(domain)
  open(cert_path, 'w').write(cert)
  if key:
    open(key_path, 'w').write(key)

def gen_nginx_config(servers):
  def make_server(domain, backend_ip, backend_port, ssl):
    sslcerts = '''
          ssl_certificate /certs/%(domain)s.crt;
          ssl_certificate_key /certs/%(domain)s.key;
    ''' % vars()
    proxy = '''
          location / {
            proxy_pass http://%(backend_ip)s:%(backend_port)s;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Forwarded-Host  $host;
            proxy_read_timeout 1h;
          }
    ''' % vars()
    if ssl == FORCE_SSL:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
          return 301 https://$host$request_uri;
        }
        server {
          server_name %(domain)s;
          listen 8443 ssl;
%(sslcerts)s
%(proxy)s
        }
      ''' % vars()
    elif ssl == USE_ACME:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
          location /.well-known/acme-challenge/ {
            alias /certs/acmetool/challenges/;
          }
          location / {
            return 301 https://$host$request_uri;
          }
        }
        server {
          server_name %(domain)s;
          listen 8443 ssl;
%(sslcerts)s
%(proxy)s
        }
      ''' % vars()
    elif ssl:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
          listen 8443 ssl;
%(sslcerts)s
%(proxy)s
        }
      ''' % vars()
    else:
      return '''
        server {
          server_name %(domain)s;
          listen 8000;
%(proxy)s
        }
      ''' % vars()

  server_blocks = ''.join(make_server(*s) for s in servers)

  return '''
    daemon off;
    user www-data;
    worker_processes 4;
    pid /dev/null;
    error_log stderr;
    events {
      worker_connections 4000;
    }
    worker_rlimit_nofile 9000;
    http {
      map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
      }
      access_log /var/log/nginx/access.log;
      error_log /var/log/nginx/error.log;
      proxy_buffering off;
      proxy_cache off;
      ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
      ssl_session_cache shared:SSL:5m;
      ssl_session_timeout 10m;
      add_header X-Content-Type-Options nosniff;
      server_tokens off;
      server {
        listen 8000;
        listen 8443 ssl;
        ssl_certificate /etc/ssl/dummy/dummy.crt;
        ssl_certificate_key /etc/ssl/dummy/dummy.key;
        return 404;
      }
%(server_blocks)s
    }
  ''' % vars()


class ServerState(object):
  """
  schema:
  data = {
    'version': 1,
    'tasks': [
      {
        'task': <task json>,
        'cid': 'abc123', # or None
      },
    ],
  }
  """
  def tasks(self):
    return self.data['tasks']

  def find_tdata_by_name(self, name):
    for tdata in self.data['tasks']:
      if tdata['task']['name'] == name:
        return tdata

  def add_task(self, task):
    assert self.find_tdata_by_name(task['name']) is None
    tdata = {'task': task, 'cid': None}
    self.data['tasks'].append(tdata)
    return tdata

  def replace_task(self, old_name, new_task):
    old_tdata = self.find_tdata_by_name(old_name)
    if old_tdata:
      self.data['tasks'].remove(old_tdata)
      cid = old_tdata['cid']
      if cid:
        try: docker('stop', cid)
        except DockerError: pass
    self.add_task(new_task)

  def __enter__(self):
    try:
      self.data = json.load(open(STATE_FILE, 'r'))
      # migrations:
      if self.data['version'] == 7:
        self.replace_task('__nginx__', NGINX_TASK)
        self.data['version'] = 8

      # future migrations:
      # if self.data['version'] == ...

    except IOError:
      self.data = {'version': VERSION, 'tasks': []}
      self.add_task(NGINX_TASK)
      self.add_task(REGISTRY_TASK)
    return self

  def save(self):
    json.dump(self.data, open(STATE_FILE + '.tmp', 'w'))
    os.rename(STATE_FILE + '.tmp', STATE_FILE)

  def __exit__(self, t, v, t2):
    self.save()


class ServerHandler(socketserver.StreamRequestHandler):
  def handle(self):
    try:
      data = json.load(self.rfile)
      result = getattr(self, 'op_' + data['op'])(data)
      out = {'success': True, 'result': result}
      self.wfile.write(json.dumps(out).encode('utf-8'))
    except:
      tb = traceback.format_exc()
      sys.stderr.write(tb + '\n')
      out = {'success': False, 'error': tb}
      self.wfile.write(json.dumps(out).encode('utf-8'))

  @staticmethod
  def get_image_name(task):
    if task.get('raw_image_name'):
      return task['raw_image_name']
    else:
      return image_in_registry(task['name'])

  @staticmethod
  def construct_docker_args(task):
    args = []

    args.append('-d')
    if 'restart_policy' in task:
      args.append('--restart='+task['restart_policy'])

    args.append('--cap-drop=all')
    for cap in task.get('caps', []):
      args.append('--cap-add='+cap)

    for vol in task.get('volumes', []):
      args.append('-v')
      host = volume_path(vol['id'])
      args.append('%s:%s' % (host, vol['container']))

    for port in task.get('exposed_ports', []):
      host = port['host']
      container = port['container']
      args.append('-p')
      if port.get('public'):
        args.append('%s:%s' % (host, container))
      else:
        expose_ip = LOCALHOST
        args.append('%s:%s:%s' % (expose_ip, host, container))

    for k, v in task.get('env', {}).items():
      args.append('-e')
      args.append('%s=%s' % (k, v))

    args.append(ServerHandler.get_image_name(task))

    args.extend(task.get('argv', []))

    return args

  @staticmethod
  def ensure_host_volumes(task):
    for vol in task.get('volumes', []):
      path = volume_path(vol['id'])
      if not os.path.isdir(path):
        os.makedirs(path)
        os.chmod(path, 0o1777)

  @staticmethod
  def reconfigure_proxy(st):
    servers = []
    acme_domains = []
    for tdata in st.tasks():
      task = tdata['task']
      domain = task.get('domain')
      port = task.get('http_port')
      if domain and port:
        ip = ipaddr_of(tdata['cid'])
        cert_path, key_path = cert_key_paths(domain)
        if task.get('force_ssl'):
          ssl = FORCE_SSL
        elif task.get('use_acme'):
          ssl = USE_ACME
          acme_domains.append(domain)
        else:
          ssl = bool(task.get('ssl_cert') and
              os.path.exists(cert_path) and os.path.exists(key_path))
        servers.append((domain, ip, port, ssl))
    cfg = gen_nginx_config(servers)

    fn = os.path.join(volume_path(NGINX_CONFIG_VOL), 'nginx.conf')
    open(fn, 'w').write(cfg)
    os.chmod(fn, 0o644)

    ServerHandler.hup_nginx(st, acme_domains)

  @staticmethod
  def hup_nginx(st, acmetool_domains=None, force_reconcile=False):
    nginx_cid = st.find_tdata_by_name(NGINX_TASK_NAME)['cid']
    if not nginx_cid: return

    if acmetool_domains:
      # mark domains as requsted by acmetool (this sets up dummy certs if we
      # don't have any yet, so nginx can start)
      try: docker('exec', nginx_cid, 'requestcerts', *acmetool_domains)
      except DockerError: pass

    # then reload nginx so it starts serving those domains
    try: docker('kill', '-s', 'HUP', nginx_cid)
    except DockerError: pass

    if acmetool_domains or force_reconcile:
      # now ask acmetool to request all certificates. this might run the reload
      # hook, which will hup nginx again, but that's ok.
      try: docker('exec', nginx_cid, 'acmetool', '--batch', 'reconcile')
      except DockerError: pass

  def op_check_running(self, data):
    with ServerState() as st:
      for task in st.data['tasks']:
        cid = task['cid']
        if cid:
          try:
            if inspect(cid, 'State', 'Running'):
              continue
          except InspectError:
            pass
          # old container probably crashed
          capture_logs(task['task']['name'], cid)
        self.run_task(st, task['task'])
        st.save()
      if data.get('reconcile'):
        ServerHandler.hup_nginx(st, force_reconcile=True)

  def health_check(self, task, cid, maxwait=30):
    port = task['http_port']
    path = task['health_check']
    if not path.startswith('/'): path = '/' + path
    for _ in range(maxwait):
      time.sleep(1)
      ip = ipaddr_of(cid)
      if not ip: continue
      url = f"http://{ip}:{port}{path}"
      try:
        with urllib.request.urlopen(url, timeout=2) as r:
          if r.getcode() == 200:
            return True
      except:
        pass
    return False

  def run_task(self, st, task, log=ignore):
    # pull latest first
    if not task.get('raw_image_name'):
      log("pulling")
      docker('pull', ServerHandler.get_image_name(task))

    stop_old_first = task.get('stop_old_first', False)

    self.ensure_host_volumes(task)

    # if we're running the proxy, ensure we have a config
    if task['name'] == NGINX_TASK_NAME:
      ServerHandler.reconfigure_proxy(st)

    # add to state and get old cid
    tdata = st.find_tdata_by_name(task['name'])
    if not tdata:
      tdata = st.add_task(task)
      log("adding new task")
    tdata['task'] = task
    old_cid = tdata['old_cid'] = tdata['cid']
    log(f"old cid was {old_cid}")

    # check if the container is already running the new image
    try:
      if old_cid and inspect(old_cid, 'State', 'Running'):
        running_image = inspect(old_cid, 'Image')
        new_image = inspect(self.get_image_name(task), 'Id')
        if running_image == new_image:
          log("image is identical")
          return
    except InspectError:
      pass

    # take down old thing (if before)
    if stop_old_first and old_cid:
      log("stopping old first")
      try: docker('stop', old_cid)
      except DockerError: pass

    # run new thing
    args = self.construct_docker_args(task)
    new_cid = tdata['cid'] = docker('run', *args).strip()

    if 'health_check' in task and 'http_port' in task:
      if not self.health_check(task, new_cid):
        # failed health check, roll back
        log("failed health check")
        docker('stop', new_cid)
        tdata['cid'] = old_cid
        return
    else:
      time.sleep(task.get('up_wait_time', 1))

    # point nginx to new thing
    if 'domain' in task:
      log("reconfiguring proxy")
      ServerHandler.reconfigure_proxy(st)

    # take down old thing (if after)
    if not stop_old_first and old_cid:
      log("stopping old")
      time.sleep(task.get('down_wait_time', 1))
      docker('stop', old_cid)

  def op_ping(self, data):
    return 'pong'

  def op_run(self, data):
    task = data['task']
    with ServerState() as st:
      log = []
      self.run_task(st, task, log.append)
      return log

  def op_stop(self, data):
    name = data['task']['name']  # only pull out name, ignore rest
    with ServerState() as st:
      tdata = st.find_tdata_by_name(name)
      if not tdata:
        return 'not found'
      task = tdata['task']
      cid = tdata['cid']
      if cid:
        stop = docker('stop', cid)
      st.data['tasks'].remove(tdata)
      reconfigured = False
      if 'domain' in task:
        reconfigured = True
        ServerHandler.reconfigure_proxy(st)
      return {'stop': stop, 'reconfigured': reconfigured}

  def op_upload_cert(self, data):
    write_cert_key(data['task']['domain'], data['cert'], data['key'])
    with ServerState() as st:
      ServerHandler.hup_nginx(st)

  def op_cleanup(self, data):
    return subprocess.getoutput('docker system prune -a -f')


def build_local_image(sources, name):
  tmpdir = tempfile.mkdtemp()
  os.chdir(tmpdir)
  for k, v in sources.items():
    open(k, 'w').write(v)
    if v.startswith('#!'):
      os.chmod(k, 0o755)
  docker('build', '-t', name, '.')
  os.chdir('/')
  shutil.rmtree(tmpdir)


def run_daemon():
  # build nginx image
  try:
    inspect(NGINX_IMAGE_NAME, 'config')
  except InspectError:
    build_local_image(NGINX_IMAGE_SOURCES, NGINX_IMAGE_NAME)

  # set up for daemon
  os.umask(0o077)
  for d in ORQ_ROOT, VOL_ROOT:
    if not os.path.isdir(d):
      os.makedirs(d)
  os.chdir(ORQ_ROOT)

  def send_check_requests():
    time.sleep(1)
    next_reconcile = time.time() + 5*86400*1.1040895
    while True:
      reconcile = time.time() > next_reconcile
      if reconcile: next_reconcile = time.time() + 5*86400*1.1040895
      try: do_client({'op': 'check_running', 'reconcile': reconcile})
      except: pass
      time.sleep(CHECK_INTERVAL)
  scr = threading.Thread(target=send_check_requests)
  scr.setDaemon(True)
  scr.start()

  socketserver.TCPServer(ORQ_ADDR, ServerHandler).serve_forever()


def install_on(host):
  if '@' not in host: host = 'root@' + host
  localpath = '/usr/local/bin/orq'
  subprocess.check_call(['scp', '-p', __file__, host+':'+localpath])
  subprocess.check_call(['ssh', host, localpath, 'local_install'])


def local_install():
  with open('/etc/systemd/system/orq.service', 'w') as f:
    f.write("""\
[Unit]
After=docker.service

[Service]
ExecStart=ORQ daemon
Restart=on-failure

[Install]
WantedBy=multi-user.target
""".replace('ORQ', os.path.abspath(__file__)))
  subprocess.check_call("""
    systemctl daemon-reload && \
    systemctl enable orq && \
    systemctl start orq""", shell=True)


class SshTunnel(object):
  def __init__(self, host):
    self.host = host

  def __enter__(self):
    args = [
        'ssh',
        '-L', 'localhost:%d:127.0.0.1:%d' % (ORQ_PORT, ORQ_PORT),
        '-L', 'localhost:%d:127.0.0.1:%d' % (REG_PORT, REG_PORT),
        '-o', 'ControlPath none',
        self.host,
        'sleep 1d',
        ]
    self.proc = subprocess.Popen(args,
        close_fds=True,
        stdin=open('/dev/null', 'r'),
        stdout=open('/dev/null', 'w'))
    while True:
      try:
        do_client({'op': 'ping'})
        break
      except socket.error:
        time.sleep(1)

  def __exit__(self, t, v, t2):
    self.proc.terminate()
    self.proc.wait()


class Cli(object):
  def handle(self, argv):
    return getattr(self, 'cmd_' + argv[0])(argv[1:])

  @staticmethod
  def load_taskfile(argv):
    tasks = json.load(open(argv[0], 'r'))
    if len(argv) > 1:
      tasks = list(filter(Cli.task_matcher(argv[1:]), tasks))
    return tasks

  @staticmethod
  def task_matcher(words):
    return lambda task: any(word in task['name'] for word in words)

  def cmd_daemon(self, argv):
    run_daemon()

  def cmd_install(self, argv):
    install_on(argv[0])

  def cmd_local_install(self, argv):
    local_install()

  def cmd_run(self, argv):
    tasks = self.load_taskfile(argv)

    print("==== BUILDING")
    for task in tasks:
      if 'dockerdir' in task:
        dockerdir = os.path.join(os.path.dirname(argv[0]), task['dockerdir'])
        image = task['name']
        regimage = image_in_registry(image)
        docker('build', '-t', image, dockerdir)
        docker('tag', image, regimage)
      elif 'nix-build' in task:
        out = subprocess.check_output(
            "$(nix-build --no-out-link %s) | docker load" % task['nix-build'],
            shell=True).decode().strip()
        assert out.startswith('Loaded image: ')
        image = out.replace('Loaded image: ', '')
        regimage = image_in_registry(task['name'])
        docker('tag', image, regimage)

    byhost = {}
    for task in tasks:
      byhost.setdefault(task['host'], []).append(task)
    byhost = list(byhost.items())

    print("==== PUSHING")
    for host, tasks in byhost:
      with SshTunnel(host):
        for task in tasks:
          if 'dockerdir' in task or 'nix-build' in task:
            docker('push', image_in_registry(task['name']))

    print("==== RUNNING")
    for host, tasks in byhost:
      with SshTunnel(host):
        for task in tasks:
          print_json(do_client({'op': 'run', 'task': task}))

  def cmd_upload_cert(self, argv):
    tasks = self.load_taskfile(argv)
    for task in tasks:
      if not task.get('ssl_cert') or not task.get('domain'):
        continue
      host = task['host']
      with SshTunnel(host):
        cert_file = os.path.join(os.path.dirname(argv[0]), task['ssl_cert'])
        key_file  = os.path.join(os.path.dirname(argv[0]), task['ssl_key'])
        cert = open(cert_file).read()
        try: key = open(key_file).read()
        except IOError: key = None
        print_json(do_client({'op': 'upload_cert', 'task': task,
                              'cert': cert, 'key': key}))

  def cmd_stop(self, argv):
    tasks = self.load_taskfile(argv)
    for task in tasks:
      host = task['host']
      with SshTunnel(host):
        print_json(do_client({'op': 'stop', 'task': task}))

  def cmd_ssh(self, argv):
    with SshTunnel(argv[0]):
      input("ssh tunnel open; press enter to close")

  def cmd_cleanup(self, argv):
    with SshTunnel(argv[0]):
      print_json(do_client({'op': 'cleanup'}))


if __name__ == '__main__':
  sys.exit(Cli().handle(sys.argv[1:]))
