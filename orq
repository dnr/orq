#!/usr/bin/python
# vim: sw=2 et

"""
goal:
  orq run squares_app.orq
  orq run dnrim.orq

  builds new docker image on dev machine.
  push to registry on host over ssh tunnel.
  start new container on host, redirect hipache, take down old container.

  orq is a process monitor, container manger, and proxy configurer.
  security all based on ssh tunnels.

running container descriptions ("task"):
  host to run on
  task name (usually same as image name) (internal to orq, not docker container name)
  image name
  domain to forward to container
  port container is listening on
  volumes:
    host path
    container path
    disposition (logs? data?)
  environment variables
  uid?

  (serialized as json)


host is running:

  outside:
    orq
      bind to localhost port 4999

  containers:
    orq-managed: (need config for these built into orq)

    hipache+redis
      bind to public port 80
    registry
      bind to localhost port 5000

    other:

    event_logger
    dnrim
    squares_mongodb
    squares_app


orq daemon:
  runs as root

  endpoints:
    run: task json
    stop: task name

  protocol:
    accept socket connection
    read json until end
    write json back
    close

  state:
    need to track:
      container ids for various things
      list of tasks that are expected to be running
    serialization:
      json file in /var/lib
"""

import os, sys, json, socket, SocketServer, threading, subprocess, time
join = os.path.join

ORQ_PORT = 4999
REG_PORT = 5000
if os.getuid() == 0:
  PUBLIC_PORT = 80
  ORQ_ROOT = '/var/lib/orq'
else:
  PUBLIC_PORT = 8000
  ORQ_ROOT = '/tmp/orq'
STATE_FILE = join(ORQ_ROOT, 'state')
VOL_ROOT = join(ORQ_ROOT, 'volumes')
LOCALHOST = '127.0.0.1'
ORQ_ADDR = (LOCALHOST, ORQ_PORT)
CHECK_INTERVAL = 5#10  FIXME

HIPACHE_TASK_NAME = '__hipache__'
HIPACHE_IMAGE_NAME = 'orq_hipache'
HIPACHE_TASK = {
    'name': HIPACHE_TASK_NAME,
    'image': HIPACHE_IMAGE_NAME,
    'volumes': [
      {'id': 'hipache_logs', 'container': '/var/log/hipache',
        'uid': 1000, 'gid': 0, 'mode': 0755}
      ],
    'exposed_ports': [
      {'host': PUBLIC_PORT, 'container': 8000, 'public': True},
      ],
    }

REGISTRY_TASK_NAME = '__registry__'
REGISTRY_TASK = {
    'name': REGISTRY_TASK_NAME,
    'image': 'stackbrew/registry',
    'volumes': [
      {'id': 'docker_registry_data', 'container': '/tmp/registry',
        'uid': 0, 'gid': 0, 'mode': 0755}
      ],
    'exposed_ports': [
      {'host': REG_PORT, 'private': REG_PORT},
      ],
    }


def volume_path(vid):
  return join(VOL_ROOT, vid)

def docker(*argv):
  argv = list(argv)
  argv[0:0] = ['docker']
  print '+', ' '.join(argv)
  return subprocess.check_output(argv)

def inspect(thing, *keys):
  data = json.loads(docker('inspect', thing))
  data = data[0]
  for k in keys:
    data = data[k]
  return data

def ipaddr_of(cid):
  return inspect(cid, 'NetworkSettings', 'IPAddress')

def image_in_registry(image):
  if '/' in image:
    return image
  else:
    return 'localhost:%d/%s' % (REG_PORT, image)

def do_client(data):
  s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
  s.connect(ORQ_ADDR)
  s.sendall(json.dumps(data))
  s.shutdown(socket.SHUT_WR)
  return json.load(s.makefile('r'))

def print_json(out):
  json.dump(out, sys.stdout, sort_keys=True,
      indent=4, separators=(',', ': '))
  print

def get_public_ip(cache=[]):
  if not cache:
    cmd = r"ifconfig eth0 | sed -ne 's/.* inet addr:\([0-9.]*\).*/\1/p'"
    output = subprocess.check_output(cmd, shell=True)
    cache.append(output.strip())
  return cache[0]


class ServerState(object):
  """
  schema:
  data = {
    'version': 1,
    'tasks': [
      {
        'task': <task json>,
        'cid': 'abc123', # or None
      },
    ],
  }
  """
  def find_tdata_by_name(self, name):
    for tdata in self.data['tasks']:
      if tdata['task']['name'] == name:
        return tdata

  def add_task(self, task):
    assert self.find_tdata_by_name(task['name']) is None
    tdata = {'task': task, 'cid': None}
    self.data['tasks'].append(tdata)
    return tdata

  def __enter__(self):
    try:
      self.data = json.load(open(STATE_FILE, 'r'))
      # TODO: check version
    except IOError:
      self.data = {'version': 1, 'tasks': []}
      self.add_task(HIPACHE_TASK)
      self.add_task(REGISTRY_TASK)
    return self

  def save(self):
    json.dump(self.data, open(STATE_FILE + '.tmp', 'w'))
    os.rename(STATE_FILE + '.tmp', STATE_FILE)

  def __exit__(self, t, v, t2):
    self.save()


class ServerHandler(SocketServer.StreamRequestHandler):
  def handle(self):
    try:
      data = json.load(self.rfile)
      print '>', data # debug
      result = getattr(self, 'op_' + data['op'])(data)
      out = {'success': True, 'result': result}
      print '<', out # debug
      json.dump(out, self.wfile)
    except:
      out = {'success': False}
      json.dump(out, self.wfile)
      raise  # FIXME

  @staticmethod
  def construct_docker_args(task):
    args = []

    args.append('-d')

    for vol in task.get('volumes', []):
      args.append('-v')
      host = volume_path(vol['id'])
      args.append('%s:%s' % (host, vol['container']))

    for port in task.get('exposed_ports', []):
      host = port['host']
      container = port['container']
      if port.get('public'):
        expose_ip = get_public_ip()
      else:
        expose_ip = LOCALHOST
      args.append('-p')
      args.append('%s:%s:%s' % (expose_ip, host, container))

    for k, v in task.get('env', {}).items():
      args.append('-e')
      args.append('%s=%s' % (k, v))

    args.append(task['image'])

    args.extend(task.get('argv', []))

    return args

  @staticmethod
  def ensure_host_volumes(task):
    for vol in task.get('volumes', []):
      path = volume_path(vol['id'])
      if not os.path.isdir(path):
        os.makedirs(path)
        os.chown(path, vol['uid'], vol['gid'])
        os.chmod(path, vol['mode'])

  @staticmethod
  def set_hipache_backend(st, domain, ip, port):
    hipache_ip = ipaddr_of(st.get_cid(HIPACHE_TASK_NAME))
    r = redis.StrictRedis(hipache_ip)

    endpoint = 'http://%s:%d' % (ip, port)
    key = 'frontend:%s' % domain

    # TODO: simplify and wrap in a transaction
    existing_keys = r.llen(key)
    if existing_keys == 0:
      r.rpush(key, domain)
    r.linsert(key, 'after', domain, endpoint)
    while r.llen(key) > 2:
      r.rpop(key)

  @staticmethod
  def clear_hipache_backend(st, domain, ip, port):
    hipache_ip = ipaddr_of(st.get_cid(HIPACHE_TASK_NAME))
    r = redis.StrictRedis(hipache_ip)
    r.delete('frontend:%s' % domain)

  def op_check_running(self, data):
    with ServerState() as st:
      for task in st.data['tasks']:
        cid = task['cid']
        if cid and inspect(cid, 'State', 'Running'):
          continue
        self.run_task(st, task['task'])
        st.save()

  def run_task(self, st, task):
    self.ensure_host_volumes(task)

    # add to state and get old cid
    tdata = st.find_tdata_by_name(task['name'])
    if not tdata:
      tdata = st.add_task(task)
    tdata['task'] = task
    old_cid = tdata['old_cid'] = tdata['cid']

    # run new thing
    args = self.construct_docker_args(task)
    new_cid = tdata['cid'] = docker('run', *args)

    time.sleep(task.get('up_wait_time', 1))

    # move hipache backend
    domain = task.get('domain')
    port = task.get('http_port')
    if domain and port:
      ip = ipaddr_of(new_cid)
      self.set_hipache_backend(st, domain, ip, port)

    # take down old thing
    if old_cid:
      time.sleep(task.get('down_wait_time', 1))
      docker('kill', old_cid)

  def op_run(self, data):
    task = data['task']
    with ServerState() as st:
      self.run_task(st, task)

  def op_stop(self, data):
    name = data['task']['name']  # only pull out name, ignore rest
    with ServerState() as st:
      tdata = st.find_tdata_by_name(name)
      if tdata:
        task = tdata['task']
        cid = tdata['cid']
        if 'domain' in task:
          self.clear_hipache_backend(task['domain'])
        if cid:
          docker('kill', cid)
        st.data['tasks'].remove(tdata)

  def op_cleanup(self, data):
    subprocess.call('''
      # delete all non-running container
      docker ps -a | awk '/Exit/ {print $1}' | xargs -r docker rm
      # delete unused images
      docker images | awk '/<none>/ {print $3}' | xargs -r docker rmi
    ''', shell=True)

def run_daemon():
  # build hipache image
  hipache_dockerdir_path = join(os.path.dirname(__file__), 'hipache')
  docker('build', '-rm', '-t', HIPACHE_IMAGE_NAME, hipache_dockerdir_path)

  # set up for daemon
  os.umask(077)
  for d in ORQ_ROOT, VOL_ROOT:
    if not os.path.isdir(d):
      os.makedirs(d)
  os.chdir(ORQ_ROOT)

  def send_check_requests():
    while True:
      time.sleep(CHECK_INTERVAL)
      try: do_client({'op': 'check_running'})
      except: pass
  scr = threading.Thread(target=send_check_requests)
  scr.setDaemon(True)
  scr.start()

  SocketServer.TCPServer(ORQ_ADDR, ServerHandler).serve_forever()


class SshTunnel(object):
  def __init__(self, host):
    self.host = host

  def __enter__(self):
    args = [
        'ssh',
        self.host,
        '-L', 'localhost:%d:127.0.0.1:%d' % (ORQ_PORT, ORQ_PORT),
        '-L', 'localhost:%d:127.0.0.1:%d' % (REG_PORT, REG_PORT),
        'sleep 1d',
        ]
    self.proc = subprocess.Popen(args,
        close_fds=True,
        stdin=open('/dev/null', 'r'),
        stdout=open('/dev/null', 'w'),
        stderr=open('/dev/null', 'w'))

  def __exit__(self, t, v, t2):
    self.proc.terminate()


class Cli(object):
  def handle(self, argv):
    return getattr(self, 'cmd_' + argv[0])(argv[1:])

  @staticmethod
  def load_taskfile(taskfile):
    return json.load(open(taskfile, 'r'))

  def cmd_daemon(self, argv):
    run_daemon()

  def cmd_run(self, argv):
    task = self.load_taskfile(argv[0])
    dockerfiledir = os.path.dirname(argv[0]) or '.'
    host = task['host']
    image = task['image']
    with SshTunnel(host):
      docker('build', '-t', image_in_registry(image), dockerfiledir)
      docker('push', image_in_registry(image))
      print_json(do_client({'op': 'run', 'task': task}))

  def cmd_stop(self, argv):
    task = self.load_taskfile(argv[0])
    host = task['host']
    with SshTunnel(host):
      print_json(do_client({'op': 'stop', 'task': task}))

  def cmd_cleanup(self, argv):
    with SshTunnel(argv[0]):
      print_json(do_client({'op': 'cleanup'}))


def main(argv):
  return Cli().handle(argv[1:])

if __name__ == '__main__':
  sys.exit(main(sys.argv))
